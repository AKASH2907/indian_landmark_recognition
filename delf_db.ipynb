{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "from six import BytesIO\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from six.moves.urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = './customdata/ResizedTrain/'\n",
    "valdir = './customdata/ResizedVal/'\n",
    "\n",
    "building_descs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = hub.Module('https://tfhub.dev/google/delf/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate method\n",
    "\n",
    "# img_name = []\n",
    "\n",
    "# for i in os.listdir(path):\n",
    "#     img_name.append('./datacluster/Train/'+i)\n",
    "\n",
    "# print img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_image(srcfile, destfile, new_width=256, new_height=256):\n",
    "#     pil_image = Image.open(srcfile)\n",
    "#     pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "#     pil_image_rgb = pil_image.convert('RGB')\n",
    "#     pil_image_rgb.save(destfile, format='JPEG', quality=90)\n",
    "#     return destfile\n",
    "# def resize_images_folder(srcfolder, destfolder='./datacluster/ResizedVal/', new_width=256, new_height=256):\n",
    "#     for srcfile in glob.iglob(os.path.join('./datacluster/Val/', '*.[Jj][Pp][Ee][Gg]')):\n",
    "#         src_basename = os.path.basename(srcfile)\n",
    "#         destfile=os.path.join(destfolder,src_basename)\n",
    "#         resize_image(srcfile, destfile, new_width, new_height)\n",
    "#     return destfolder\n",
    "\n",
    "def get_resized_db_image_paths(destfolder=trainpath):\n",
    "    return sorted(list(glob.iglob(os.path.join(destfolder, '*.[Jj][Pp][Ee][Gg]'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_images_folder('./datacluster/Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./customdata/ResizedTrain/Buddhist_1.jpeg', './customdata/ResizedTrain/Buddhist_2.jpeg', './customdata/ResizedTrain/Buddhist_4.jpeg', './customdata/ResizedTrain/Dravidian_1.jpeg', './customdata/ResizedTrain/Dravidian_3.jpeg', './customdata/ResizedTrain/Dravidian_6.jpeg', './customdata/ResizedTrain/Kalinga_75.jpeg', './customdata/ResizedTrain/Kalinga_77.jpeg', './customdata/ResizedTrain/Kalinga_79.jpeg', './customdata/ResizedTrain/Mughal_84.jpeg', './customdata/ResizedTrain/Mughal_86.jpeg', './customdata/ResizedTrain/Mughal_94.jpeg']\n"
     ]
    }
   ],
   "source": [
    "# resize_images_folder(path)\n",
    "db_images = get_resized_db_image_paths()\n",
    "print (db_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def accumulate(inputs, func):\n",
    "    itr = iter(inputs)\n",
    "    prev = next(itr)\n",
    "    for cur in itr:\n",
    "        yield prev\n",
    "        prev = func(prev, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_placeholder = tf.placeholder(\n",
    "    tf.float32, shape=(None, None, 3), name='input_image')\n",
    "\n",
    "module_inputs = {\n",
    "    'image': image_placeholder,\n",
    "    'score_threshold': 100.0,\n",
    "    'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
    "    'max_feature_num': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number_of_files = len([item for item in os.listdir(path) if os.path.isfile(os.path.join(path, item))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_input_fn(image_files):\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        image_files, shuffle=False)\n",
    "    reader = tf.WholeFileReader()\n",
    "    _, value = reader.read(filename_queue)\n",
    "    image_tf = tf.image.decode_jpeg(value, channels=3)\n",
    "    return tf.image.convert_image_dtype(image_tf, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Buddhist_1.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Buddhist_2.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Buddhist_4.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Dravidian_1.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Dravidian_3.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Dravidian_6.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Kalinga_75.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Kalinga_77.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Kalinga_79.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Mughal_84.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Mughal_86.jpeg\n",
      "Extracting locations and descriptors from ./customdata/ResizedTrain/Mughal_94.jpeg\n"
     ]
    }
   ],
   "source": [
    "module_outputs = m(module_inputs, as_dict=True)\n",
    "\n",
    "image_tf = image_input_fn(db_images)\n",
    "\n",
    "with tf.train.MonitoredSession() as sess:\n",
    "    results_dict = {}  # Stores the locations and their descriptors for each image\n",
    "    for image_path in db_images:\n",
    "        image = sess.run(image_tf)\n",
    "        print('Extracting locations and descriptors from %s' % image_path)\n",
    "        building_descs.append(image_path.split('_')[0].split('/')[-1])\n",
    "        results_dict[image_path] = sess.run(\n",
    "            [module_outputs['locations'], module_outputs['descriptors']],\n",
    "            feed_dict={image_placeholder: image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_agg = np.concatenate([results_dict[img][0] for img in db_images])\n",
    "descriptors_agg = np.concatenate([results_dict[img][1] for img in db_images])\n",
    "accumulated_indexes_boundaries = list(accumulate([results_dict[img][0].shape[0] for img in db_images], operator.add))\n",
    "\n",
    "d_tree = cKDTree(descriptors_agg) # build the KD tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205, 325, 518, 699, 944, 1129, 1316, 1599, 1850, 2092, 2325]\n"
     ]
    }
   ],
   "source": [
    "print (accumulated_indexes_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_locations_and_descriptors(image_path):\n",
    "    tf.reset_default_graph()\n",
    "    tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "    m = hub.Module('https://tfhub.dev/google/delf/1')\n",
    "\n",
    "    # The module operates on a single image at a time, so define a placeholder to\n",
    "    # feed an arbitrary image in.\n",
    "    image_placeholder = tf.placeholder(\n",
    "        tf.float32, shape=(None, None, 3), name='input_image')\n",
    "\n",
    "    module_inputs = {\n",
    "        'image': image_placeholder,\n",
    "        'score_threshold': 100.0,\n",
    "        'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
    "        'max_feature_num': 1000,\n",
    "    }\n",
    "\n",
    "    module_outputs = m(module_inputs, as_dict=True)\n",
    "\n",
    "    image_tf = image_input_fn([image_path])\n",
    "\n",
    "    with tf.train.MonitoredSession() as sess:\n",
    "        image = sess.run(image_tf)\n",
    "        print('Extracting locations and descriptors from %s' % image_path)\n",
    "        return sess.run(\n",
    "            [module_outputs['locations'], module_outputs['descriptors']],\n",
    "            feed_dict={image_placeholder: image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_index_2_accumulated_indexes(index, accumulated_indexes_boundaries):\n",
    "    '''\n",
    "    Image index to accumulated/aggregated locations/descriptors pair indexes.\n",
    "    '''\n",
    "    if index > len(accumulated_indexes_boundaries) - 1:\n",
    "        return None\n",
    "    accumulated_index_start = None\n",
    "    accumulated_index_end = None\n",
    "    if index == 0:\n",
    "        accumulated_index_start = 0\n",
    "        accumulated_index_end = accumulated_indexes_boundaries[index]\n",
    "    else:\n",
    "        accumulated_index_start = accumulated_indexes_boundaries[index-1]\n",
    "        accumulated_index_end = accumulated_indexes_boundaries[index]\n",
    "    return np.arange(accumulated_index_start,accumulated_index_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations_2_use(image_db_index, k_nearest_indices, accumulated_indexes_boundaries):\n",
    "    '''\n",
    "    Get a pair of locations to use, the query image to the database image with given index.\n",
    "    Return: a tuple of 2 numpy arrays, the locations pair.\n",
    "    '''\n",
    "    image_accumulated_indexes = image_index_2_accumulated_indexes(image_db_index, accumulated_indexes_boundaries)\n",
    "    locations_2_use_query = []\n",
    "    locations_2_use_db = []\n",
    "    for i, row in enumerate(k_nearest_indices):\n",
    "        for acc_index in row:\n",
    "            if acc_index in image_accumulated_indexes:\n",
    "                locations_2_use_query.append(query_image_locations[i])\n",
    "                locations_2_use_db.append(locations_agg[acc_index])\n",
    "                break\n",
    "    return np.array(locations_2_use_query), np.array(locations_2_use_db)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "tot = 0\n",
    "distance_threshold = 0.8\n",
    "# K nearest neighbors\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting locations and descriptors from ./customdata/ResizedVal/Buddhist_727.jpeg\n",
      "Found inliers for image 0 -> 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagnik/.local/lib/python3.5/site-packages/skimage/transform/_geometric.py:684: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  H.flat[list(self._coeffs) + [8]] = - V[-1, :-1] / V[-1, -1]\n",
      "/home/sagnik/.local/lib/python3.5/site-packages/skimage/transform/_geometric.py:684: RuntimeWarning: invalid value encountered in true_divide\n",
      "  H.flat[list(self._coeffs) + [8]] = - V[-1, :-1] / V[-1, -1]\n",
      "/home/sagnik/.local/lib/python3.5/site-packages/skimage/measure/fit.py:831: RuntimeWarning: invalid value encountered in less\n",
      "  sample_model_inliers = sample_model_residuals < residual_threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found inliers for image 1 -> 3\n",
      "Found inliers for image 2 -> 21\n",
      "Found inliers for image 4 -> 2\n",
      "Found inliers for image 6 -> 6\n",
      "Found inliers for image 7 -> 2\n",
      "Found inliers for image 8 -> 2\n",
      "Found inliers for image 9 -> 6\n",
      "Found inliers for image 10 -> 8\n",
      "[{'index': 0, 'inliers': 10}, {'index': 1, 'inliers': 3}, {'index': 2, 'inliers': 21}, {'index': 4, 'inliers': 2}, {'index': 6, 'inliers': 6}, {'index': 7, 'inliers': 2}, {'index': 8, 'inliers': 2}, {'index': 9, 'inliers': 6}, {'index': 10, 'inliers': 8}]\n",
      "Best guess for this image: Buddhist\n",
      "Extracting locations and descriptors from ./customdata/ResizedVal/Dravidian_691.jpeg\n",
      "Found inliers for image 0 -> 4\n",
      "Found inliers for image 2 -> 9\n",
      "Found inliers for image 3 -> 11\n",
      "Found inliers for image 4 -> 16\n",
      "Found inliers for image 5 -> 8\n",
      "Found inliers for image 6 -> 8\n",
      "Found inliers for image 7 -> 13\n",
      "Found inliers for image 8 -> 6\n",
      "Found inliers for image 9 -> 3\n",
      "Found inliers for image 10 -> 9\n",
      "[{'index': 0, 'inliers': 4}, {'index': 2, 'inliers': 9}, {'index': 3, 'inliers': 11}, {'index': 4, 'inliers': 16}, {'index': 5, 'inliers': 8}, {'index': 6, 'inliers': 8}, {'index': 7, 'inliers': 13}, {'index': 8, 'inliers': 6}, {'index': 9, 'inliers': 3}, {'index': 10, 'inliers': 9}]\n",
      "Best guess for this image: Dravidian\n",
      "Extracting locations and descriptors from ./customdata/ResizedVal/Kalinga_970.jpeg\n",
      "Found inliers for image 0 -> 3\n",
      "Found inliers for image 3 -> 3\n",
      "Found inliers for image 4 -> 4\n",
      "Found inliers for image 5 -> 3\n",
      "Found inliers for image 7 -> 8\n",
      "Found inliers for image 8 -> 9\n",
      "[{'index': 0, 'inliers': 3}, {'index': 3, 'inliers': 3}, {'index': 4, 'inliers': 4}, {'index': 5, 'inliers': 3}, {'index': 7, 'inliers': 8}, {'index': 8, 'inliers': 9}]\n",
      "Best guess for this image: Kalinga\n",
      "Extracting locations and descriptors from ./customdata/ResizedVal/Mughal_677.jpeg\n",
      "Found inliers for image 0 -> 5\n",
      "Found inliers for image 2 -> 6\n",
      "Found inliers for image 3 -> 4\n",
      "Found inliers for image 5 -> 5\n",
      "Found inliers for image 6 -> 8\n",
      "Found inliers for image 7 -> 4\n",
      "Found inliers for image 8 -> 5\n",
      "Found inliers for image 9 -> 11\n",
      "Found inliers for image 10 -> 12\n",
      "[{'index': 0, 'inliers': 5}, {'index': 2, 'inliers': 6}, {'index': 3, 'inliers': 4}, {'index': 5, 'inliers': 5}, {'index': 6, 'inliers': 8}, {'index': 7, 'inliers': 4}, {'index': 8, 'inliers': 5}, {'index': 9, 'inliers': 11}, {'index': 10, 'inliers': 12}]\n",
      "Best guess for this image: Mughal\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for im in os.listdir(valdir):\n",
    "    \n",
    "    query_image_locations, query_image_descriptors = compute_locations_and_descriptors(valdir+im)\n",
    "    distances, indices = d_tree.query(\n",
    "    query_image_descriptors, distance_upper_bound=distance_threshold, k = K, n_jobs=-1)\n",
    "\n",
    "    # Find the list of unique accumulated/aggregated indexes\n",
    "    unique_indices = np.array(list(set(indices.flatten())))\n",
    "\n",
    "    unique_indices.sort()\n",
    "    if unique_indices[-1] == descriptors_agg.shape[0]:\n",
    "        unique_indices = unique_indices[:-1]\n",
    "        \n",
    "    unique_image_indexes = np.array(\n",
    "    list(set([np.argmax([np.array(accumulated_indexes_boundaries)>index]) \n",
    "              for index in unique_indices])))\n",
    "    unique_image_indexes\n",
    "    \n",
    "    inliers_counts = []\n",
    "    \n",
    "    img_1 = mpimg.imread(valdir+im)\n",
    "    for index in unique_image_indexes:\n",
    "        locations_2_use_query, locations_2_use_db = get_locations_2_use(index, indices, accumulated_indexes_boundaries)\n",
    "        # Perform geometric verification using RANSAC.\n",
    "        _, inliers = ransac(\n",
    "            (locations_2_use_db, locations_2_use_query), # source and destination coordinates\n",
    "            AffineTransform,\n",
    "            min_samples=3,\n",
    "            residual_threshold=20,\n",
    "            max_trials=1000)\n",
    "        # If no inlier is found for a database candidate image, we continue on to the next one.\n",
    "        if inliers is None or len(inliers) == 0:\n",
    "            continue\n",
    "        # the number of inliers as the score for retrieved images.\n",
    "        inliers_counts.append({\"index\": index, \"inliers\": sum(inliers)})\n",
    "        print('Found inliers for image {} -> {}'.format(index, sum(inliers)))\n",
    "    \n",
    "    print (inliers_counts)\n",
    "    \n",
    "    top_match = sorted(inliers_counts, key=lambda k: k['inliers'], reverse=True)[0]\n",
    "\n",
    "    index = top_match['index']\n",
    "    print ('Best guess for this image:', building_descs[index])\n",
    "    if im.split('_')[0]== building_descs[index]:\n",
    "        count = count+1\n",
    "        \n",
    "    locations_2_use_query, locations_2_use_db = get_locations_2_use(index, indices, accumulated_indexes_boundaries)\n",
    "    # Perform geometric verification using RANSAC.\n",
    "    _, inliers = ransac(\n",
    "        (locations_2_use_db, locations_2_use_query), # source and destination coordinates\n",
    "        AffineTransform,\n",
    "        min_samples=3,\n",
    "        residual_threshold=20,\n",
    "        max_trials=1000)\n",
    "    tot= tot+1\n",
    "    \n",
    "print ('Accuracy:', count/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
